{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c436c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 11:50:39.897246: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-07-26 11:50:39.900081: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-26 11:50:39.900091: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf21bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5fd6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicago', 'las-vegas', 'london', 'dubai', 'new-york-city', 'shanghai', 'new-delhi', 'san-francisco', 'montreal', '.DS_Store', 'beijing']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"word2vec_dataset/word2vec_dataset/review_hotels/data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5aafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltext=[]\n",
    "path=\"word2vec_dataset/word2vec_dataset/review_hotels/data\"\n",
    "for folders in os.listdir(path):\n",
    "    if not folders[0].isalnum():\n",
    "        continue\n",
    "    for filename in os.listdir(path + '/' + folders):\n",
    "        with open(os.path.join(path + '/' + folders,filename),'r',errors='ignore') as f:\n",
    "            for sentence in f.readlines():\n",
    "                alltext.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86008269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ups and Downs\\tI was in Chicago for business and stayed with another colleague in a room. The room was very clean, but the hotel is a bit cheap when it comes to bathroom amenities. There were two of us booked in the room--why only one bath robe? Turn down service was spotty. One night we had a drink in the room; our wine glasses were taken but never returned until we called. There is a service called &quot;Delighted to Service&quot;----the person who answered when I called apparently wasn't told you were supposed to be friendly when a hotel guest calls!The bar in the hotel, Novo is a complete rip-off. One night 4 of us met for drinks. 2 of my friends ordered the special martinis at $11 each. When the first one arrived, we laughed and joked that the waitress must have been thristy since it wasn't even 3/4 full; the second maritini was also less then 3/4 full so we joked that the waitress must have tripped and spilled some. The friend who ordered an expensive wine got about 2 inches of wine, if that.The hotel does have great facilities for conferences which is why we were there. It is not cheap. I might stay there again, but if they want to rate the hotel as a 4 star, the overall experience needs to be upgraded.\\t\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltext[0][alltext[0].index('\\t')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f51fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(alltext)\n",
    "no_date_text=[]\n",
    "for i in range(n):\n",
    "    try:\n",
    "        no_date_text.append(alltext[i][alltext[i].index('\\t')+1:])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c554e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemma=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb92f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [lemma.lemmatize(word) for word in tokens if word not in stopwords and word.isalpha()]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87d49299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255138it [01:38, 2581.10it/s]\n"
     ]
    }
   ],
   "source": [
    "word_lists = []\n",
    "all_words=Counter()\n",
    "maxlen=30\n",
    "\n",
    "for i,text in tqdm(enumerate(no_date_text)):\n",
    "    no_date_text[i] = clean_text(text)[:maxlen]\n",
    "    for word in no_date_text[i]:\n",
    "        all_words[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa4b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "uniq_words=[]\n",
    "for w,i in sorted(all_words.items(),key=lambda x:x[1],reverse=True):\n",
    "    if k>9999:\n",
    "        break\n",
    "    uniq_words.append(w)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca2cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 2323585.40it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_word_dict = {}\n",
    "for i, word in tqdm(enumerate(uniq_words)):\n",
    "    unique_word_dict.update({\n",
    "        word: i\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5081979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel 0\n",
      "room 1\n",
      "great 2\n",
      "location 3\n",
      "stayed 4\n",
      "stay 5\n",
      "night 6\n",
      "good 7\n",
      "staff 8\n",
      "clean 9\n",
      "nice 10\n",
      "time 11\n",
      "one 12\n",
      "service 13\n",
      "bed 14\n",
      "place 15\n",
      "small 16\n",
      "excellent 17\n",
      "booked 18\n",
      "friendly 19\n",
      "london 20\n"
     ]
    }
   ],
   "source": [
    "for w,i in unique_word_dict.items():\n",
    "    if i>20:\n",
    "        break\n",
    "    print(w,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cecbb1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 255138/255138 [01:24<00:00, 3015.18it/s]\n"
     ]
    }
   ],
   "source": [
    "window=2\n",
    "\n",
    "word_lists = []\n",
    "\n",
    "for j in tqdm(range(len(no_date_text))):\n",
    "    no_date_text[j]=[word for word in no_date_text[j] if word in uniq_words]\n",
    "    for i, word in enumerate(no_date_text[j]):\n",
    "        for w in range(window):\n",
    "            if i + 1 + w < len(no_date_text[j]): \n",
    "                word_lists.append([word] + [no_date_text[j][(i + 1 + w)]])    \n",
    "            if i - w - 1 >= 0:\n",
    "                word_lists.append([word] + [no_date_text[j][(i - w - 1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b2ac29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24557670"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "437c51b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=len(unique_word_dict)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c5a58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.sparse import SparseTensor as spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3207aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 11:54:03.751229: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-26 11:54:03.751265: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-26 11:54:03.751287: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (localhost.localdomain): /proc/driver/nvidia/version does not exist\n",
      "2022-07-26 11:54:03.751987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x=spa(indices=[[i,unique_word_dict[word_lists[i][0]]] for i in range(128)],values=[1 for i in range(128)],dense_shape=[128,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c4afe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e0f78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, word_lists, unique_word_dict, batch_size=128,shuffle=False):\n",
    "        'Initialization'\n",
    "        self.word_lists = word_lists\n",
    "        self.batch_size = batch_size\n",
    "        self.unique_word_dict = unique_word_dict\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.word_lists) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.word_lists[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.word_lists))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, word_lists_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        n=len(self.unique_word_dict)\n",
    "        n1=len(word_lists_temp)\n",
    "        \n",
    "        X = spa(indices=[[i,self.unique_word_dict[word_lists_temp[i][0]]] for i in range(n1)],values=[1 for i in range(n1)],dense_shape=[n1,n])\n",
    "        Y = spa(indices=[[i,self.unique_word_dict[word_lists_temp[i][1]]] for i in range(n1)],values=[1 for i in range(n1)],dense_shape=[n1,n])\n",
    "\n",
    "        #for i, word_list in enumerate(word_lists_temp):\n",
    "\n",
    "            #X_row = np.zeros(n)\n",
    "            #Y_row = np.zeros(n)\n",
    "\n",
    "            #X_row[self.unique_word_dict[word_list[0]]] = 1\n",
    "\n",
    "            #Y_row[self.unique_word_dict[word_list[1]]] = 1\n",
    "            #X_row=spa(indices=[[self.unique_word_dict[word_list[i][0]] for i in range(n1)]],values=[1 for i in range(n1)],dense_shape=[n1,n])\n",
    "            #Y_row=spa(indices=[[self.unique_word_dict[word_list[1]]]],values=[1],dense_shape=[n])\n",
    "\n",
    "            #X.append(X_row)\n",
    "            #Y.append(Y_row)\n",
    "\n",
    "        return X,tf.sparse.to_dense(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70ad6670",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40264/11246289.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n",
      "/home/aditya/.local/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 25), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191856/191856 [==============================] - 3176s 17ms/step - loss: 6.6192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81d8571990>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "inp_out_nodes=len(unique_word_dict)\n",
    "embed_size = 25\n",
    "\n",
    "data_generator=DataGenerator(word_lists,unique_word_dict,batch_size=128)\n",
    "\n",
    "inp = Input(shape=(inp_out_nodes,),sparse=True)\n",
    "x = Dense(units=embed_size, activation='linear')(inp)\n",
    "x = Dense(units=inp_out_nodes, activation='softmax')(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=data_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6,\n",
    "    epochs=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7ca31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()[0]\n",
    "\n",
    "embedding_dict = {}\n",
    "for word in uniq_words: \n",
    "    embedding_dict.update({\n",
    "        word: weights[unique_word_dict.get(word)]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edd6e54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_2 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: w2v_w5model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: w2v_w5model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('w2v_w5model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6626eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol=embedding_dict['polite']\n",
    "dirt=embedding_dict['dirty']\n",
    "fra=embedding_dict['france']\n",
    "sho=embedding_dict['shocked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c73482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "def cossim(x,y):\n",
    "    return np.dot(x,y)/norm(x)*norm(y)\n",
    "def top(x):\n",
    "    tops=[]\n",
    "    for w,i in embedding_dict.items():\n",
    "        tops.append([cossim(i,x),w])\n",
    "    tops.sort(reverse=True)\n",
    "    return tops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3807194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1565533, 'polite'], [5.936247, 'courteous'], [5.7218723, 'informative'], [5.7175884, 'smiley'], [5.6953373, 'professional'], [5.6798983, 'freindly'], [5.6762376, 'friendly'], [5.6517563, 'personable'], [5.6475177, 'courtious'], [5.6463637, 'accommodating']]\n"
     ]
    }
   ],
   "source": [
    "print(top(pol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7edc28bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0093656, 'dirty'], [5.709279, 'filthy'], [5.5923386, 'smelly'], [5.5772266, 'moldy'], [5.5136285, 'unclean'], [5.4892893, 'stinky'], [5.370372, 'gross'], [5.3120003, 'carpet'], [5.310087, 'hole'], [5.306463, 'stained']]\n"
     ]
    }
   ],
   "source": [
    "print(top(dirt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb119816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2151058, 'france'], [1.9428515, 'rajasthan'], [1.9242859, 'ireland'], [1.923313, 'india'], [1.9155867, 'sydney'], [1.9119023, 'sonoma'], [1.9090952, 'canada'], [1.8196089, 'kuoni'], [1.8059552, 'edinburgh'], [1.8055127, 'usa']]\n"
     ]
    }
   ],
   "source": [
    "print(top(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efb1b670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.760999, 'shocked'], [1.5220942, 'horrified'], [1.3938911, 'heavily'], [1.3780063, 'already'], [1.3669505, 'suspicious'], [1.3649032, 'unfortunately'], [1.3604099, 'dissapointed'], [1.3457959, 'initially'], [1.3436953, 'laughed'], [1.3413905, 'saw']]\n"
     ]
    }
   ],
   "source": [
    "print(top(sho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0cf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(no_date_text)):\n",
    "    no_date_text[i]=gensim.utils.simple_preprocess(no_date_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a040f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ups',\n",
       " 'and',\n",
       " 'downs',\n",
       " 'was',\n",
       " 'in',\n",
       " 'chicago',\n",
       " 'for',\n",
       " 'business',\n",
       " 'and',\n",
       " 'stayed',\n",
       " 'with',\n",
       " 'another',\n",
       " 'colleague',\n",
       " 'in',\n",
       " 'room',\n",
       " 'the',\n",
       " 'room',\n",
       " 'was',\n",
       " 'very',\n",
       " 'clean',\n",
       " 'but',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'is',\n",
       " 'bit',\n",
       " 'cheap',\n",
       " 'when',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'to',\n",
       " 'bathroom',\n",
       " 'amenities',\n",
       " 'there',\n",
       " 'were',\n",
       " 'two',\n",
       " 'of',\n",
       " 'us',\n",
       " 'booked',\n",
       " 'in',\n",
       " 'the',\n",
       " 'room',\n",
       " 'why',\n",
       " 'only',\n",
       " 'one',\n",
       " 'bath',\n",
       " 'robe',\n",
       " 'turn',\n",
       " 'down',\n",
       " 'service',\n",
       " 'was',\n",
       " 'spotty',\n",
       " 'one',\n",
       " 'night',\n",
       " 'we',\n",
       " 'had',\n",
       " 'drink',\n",
       " 'in',\n",
       " 'the',\n",
       " 'room',\n",
       " 'our',\n",
       " 'wine',\n",
       " 'glasses',\n",
       " 'were',\n",
       " 'taken',\n",
       " 'but',\n",
       " 'never',\n",
       " 'returned',\n",
       " 'until',\n",
       " 'we',\n",
       " 'called',\n",
       " 'there',\n",
       " 'is',\n",
       " 'service',\n",
       " 'called',\n",
       " 'quot',\n",
       " 'delighted',\n",
       " 'to',\n",
       " 'service',\n",
       " 'quot',\n",
       " 'the',\n",
       " 'person',\n",
       " 'who',\n",
       " 'answered',\n",
       " 'when',\n",
       " 'called',\n",
       " 'apparently',\n",
       " 'wasn',\n",
       " 'told',\n",
       " 'you',\n",
       " 'were',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'friendly',\n",
       " 'when',\n",
       " 'hotel',\n",
       " 'guest',\n",
       " 'calls',\n",
       " 'the',\n",
       " 'bar',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'novo',\n",
       " 'is',\n",
       " 'complete',\n",
       " 'rip',\n",
       " 'off',\n",
       " 'one',\n",
       " 'night',\n",
       " 'of',\n",
       " 'us',\n",
       " 'met',\n",
       " 'for',\n",
       " 'drinks',\n",
       " 'of',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'ordered',\n",
       " 'the',\n",
       " 'special',\n",
       " 'martinis',\n",
       " 'at',\n",
       " 'each',\n",
       " 'when',\n",
       " 'the',\n",
       " 'first',\n",
       " 'one',\n",
       " 'arrived',\n",
       " 'we',\n",
       " 'laughed',\n",
       " 'and',\n",
       " 'joked',\n",
       " 'that',\n",
       " 'the',\n",
       " 'waitress',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'thristy',\n",
       " 'since',\n",
       " 'it',\n",
       " 'wasn',\n",
       " 'even',\n",
       " 'full',\n",
       " 'the',\n",
       " 'second',\n",
       " 'maritini',\n",
       " 'was',\n",
       " 'also',\n",
       " 'less',\n",
       " 'then',\n",
       " 'full',\n",
       " 'so',\n",
       " 'we',\n",
       " 'joked',\n",
       " 'that',\n",
       " 'the',\n",
       " 'waitress',\n",
       " 'must',\n",
       " 'have',\n",
       " 'tripped',\n",
       " 'and',\n",
       " 'spilled',\n",
       " 'some',\n",
       " 'the',\n",
       " 'friend',\n",
       " 'who',\n",
       " 'ordered',\n",
       " 'an',\n",
       " 'expensive',\n",
       " 'wine',\n",
       " 'got',\n",
       " 'about',\n",
       " 'inches',\n",
       " 'of',\n",
       " 'wine',\n",
       " 'if',\n",
       " 'that',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'does',\n",
       " 'have',\n",
       " 'great',\n",
       " 'facilities',\n",
       " 'for',\n",
       " 'conferences',\n",
       " 'which',\n",
       " 'is',\n",
       " 'why',\n",
       " 'we',\n",
       " 'were',\n",
       " 'there',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'cheap',\n",
       " 'might',\n",
       " 'stay',\n",
       " 'there',\n",
       " 'again',\n",
       " 'but',\n",
       " 'if',\n",
       " 'they',\n",
       " 'want',\n",
       " 'to',\n",
       " 'rate',\n",
       " 'the',\n",
       " 'hotel',\n",
       " 'as',\n",
       " 'star',\n",
       " 'the',\n",
       " 'overall',\n",
       " 'experience',\n",
       " 'needs',\n",
       " 'to',\n",
       " 'be',\n",
       " 'upgraded']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_date_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8575de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(no_date_text,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ac3382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9562245607376099),\n",
       " ('curtious', 0.9254128932952881),\n",
       " ('cordial', 0.9228877425193787),\n",
       " ('curteous', 0.9179827570915222),\n",
       " ('friendly', 0.8865291476249695),\n",
       " ('professional', 0.8803302645683289),\n",
       " ('personable', 0.880230188369751),\n",
       " ('obliging', 0.876288115978241),\n",
       " ('freindly', 0.8689395785331726),\n",
       " ('attentive', 0.8673774600028992)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('polite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edf1f089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9403677582740784),\n",
       " ('cordial', 0.9175040125846863),\n",
       " ('curtious', 0.8974000811576843),\n",
       " ('curteous', 0.894274890422821),\n",
       " ('friendly', 0.8864861130714417),\n",
       " ('personable', 0.8689129948616028),\n",
       " ('courtious', 0.8669386506080627),\n",
       " ('professional', 0.8653585314750671),\n",
       " ('freindly', 0.8647214770317078),\n",
       " ('attentive', 0.8505169153213501)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('polite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aead7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8850131034851074),\n",
       " ('unclean', 0.8443936109542847),\n",
       " ('grubby', 0.8276762366294861),\n",
       " ('dusty', 0.8143419027328491),\n",
       " ('smelly', 0.8079279065132141),\n",
       " ('stained', 0.7973206639289856),\n",
       " ('dingy', 0.7956437468528748),\n",
       " ('grimy', 0.7954571843147278),\n",
       " ('threadbare', 0.7616309523582458),\n",
       " ('grungy', 0.7595184445381165)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('dirty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14733e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8956348299980164),\n",
       " ('unclean', 0.8347494006156921),\n",
       " ('dusty', 0.8254992961883545),\n",
       " ('grubby', 0.8135543465614319),\n",
       " ('stained', 0.8135532736778259),\n",
       " ('smelly', 0.8127628564834595),\n",
       " ('dingy', 0.8025403022766113),\n",
       " ('grimy', 0.7875556349754333),\n",
       " ('gross', 0.769194483757019),\n",
       " ('mouldy', 0.7645899057388306)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('dirty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "713ac0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.7601078152656555),\n",
       " ('hawaii', 0.7335811257362366),\n",
       " ('barcelona', 0.7212272882461548),\n",
       " ('edinburgh', 0.7177729606628418),\n",
       " ('manchester', 0.7142756581306458),\n",
       " ('canada', 0.7137922048568726),\n",
       " ('mexico', 0.7136322259902954),\n",
       " ('greece', 0.7028810381889343),\n",
       " ('rome', 0.6963257193565369),\n",
       " ('england', 0.694165050983429)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd5fbb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada', 0.7614089846611023),\n",
       " ('hawaii', 0.7559431195259094),\n",
       " ('germany', 0.7554485201835632),\n",
       " ('russia', 0.7344716787338257),\n",
       " ('spain', 0.7289267778396606),\n",
       " ('detroit', 0.7277833223342896),\n",
       " ('boston', 0.7261947393417358),\n",
       " ('manchester', 0.7240197062492371),\n",
       " ('los', 0.7203864455223083),\n",
       " ('ottawa', 0.7149811387062073)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9f363b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dismayed', 0.8659629821777344),\n",
       " ('horrified', 0.8553714752197266),\n",
       " ('appalled', 0.8544608950614929),\n",
       " ('astonished', 0.8502187132835388),\n",
       " ('amazed', 0.8499859571456909),\n",
       " ('suprised', 0.8346281051635742),\n",
       " ('surprised', 0.8211231231689453),\n",
       " ('stunned', 0.818147599697113),\n",
       " ('surprized', 0.8072366118431091),\n",
       " ('astounded', 0.7653063535690308)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('shocked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f948b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('astonished', 0.8625437617301941),\n",
       " ('appalled', 0.8525459170341492),\n",
       " ('horrified', 0.850727915763855),\n",
       " ('amazed', 0.8442299365997314),\n",
       " ('stunned', 0.834455132484436),\n",
       " ('dismayed', 0.8310640454292297),\n",
       " ('suprised', 0.804319441318512),\n",
       " ('surprised', 0.7833690643310547),\n",
       " ('astounded', 0.7687271237373352),\n",
       " ('surprized', 0.7598392963409424)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('shocked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5725170c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1988171 , -0.9674909 ,  0.64097   , -0.71369845, -0.00628295,\n",
       "        2.1619508 ,  1.5266845 ,  0.24826671, -3.128817  , -3.4203453 ,\n",
       "       -2.6994023 ,  1.4151658 ,  3.382561  ,  0.8212804 , -1.8087522 ,\n",
       "        0.20338462,  0.51118785,  0.16701764,  1.3731269 ,  1.0951844 ,\n",
       "        2.220896  ,  1.8583843 ,  1.3731807 ,  0.72523826, -1.4466767 ,\n",
       "        0.43909648, -2.9454157 ,  0.00636258, -0.87504333,  1.357516  ,\n",
       "        0.88279504,  3.304704  ,  1.71506   , -0.7912113 , -1.3957821 ,\n",
       "        1.512245  , -0.9164039 , -1.5361773 , -1.6478198 , -0.00931805,\n",
       "        0.2834988 , -1.0733864 ,  0.45020404,  2.9922414 ,  2.6350858 ,\n",
       "       -1.2810483 ,  3.0789678 , -4.661094  ,  2.473212  , -1.2049787 ,\n",
       "        2.6635103 ,  1.3205016 ,  1.3404276 ,  2.5705771 , -2.1999757 ,\n",
       "       -2.4327166 , -1.8434448 , -0.7479542 , -3.8086164 , -0.4265809 ,\n",
       "       -2.3046997 , -4.9821773 ,  2.0753124 ,  0.43855223,  0.84447545,\n",
       "        1.0311258 , -1.1947426 , -0.35087544, -0.22979113, -0.41628447,\n",
       "       -0.97984743,  2.8220966 , -0.7807304 ,  1.3952289 , -0.5814316 ,\n",
       "       -0.63179475,  2.1407678 ,  1.4778484 ,  2.1045177 , -1.0544447 ,\n",
       "        0.43748796, -0.01392812,  0.8795094 , -0.43588218,  2.2832394 ,\n",
       "       -4.1593776 ,  0.059416  ,  0.5095754 , -3.1623514 ,  0.42051697,\n",
       "       -1.2185621 , -0.06691755, -2.259886  ,  1.1514794 , -1.6298714 ,\n",
       "        1.8737965 ,  0.6819356 ,  1.8371899 , -3.513728  , -3.417025  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['polite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a8f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
