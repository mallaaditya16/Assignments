{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Digit recognizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**: MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Build a deep learning model to predict, which number a hand written digit is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By using Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #nn.module is the parent class for all pytorch models, it has some inbuilt functionalities which calculates gradients\n",
    "    \n",
    "    def __init__(self):# constructor\n",
    "        \n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        # 1 input layer of 784(28*28 flattened) and a hidden layer with 30 neuron and finally output layer of 10 neurons\n",
    "        self.fc1=nn.Linear(784,30)\n",
    "        self.drop=nn.Dropout(0.2)\n",
    "        self.fc2=nn.Linear(30,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x-shape [64,784] [batchsize,inputsize]\n",
    "        #layer-1\n",
    "        l1=self.fc1(x)# l1-shape [64,30]\n",
    "        \n",
    "        #activation function-1\n",
    "        al1=torch.sigmoid(l1)#al1-shape[64,30]\n",
    "        \n",
    "        #layer-2\n",
    "        l2=self.fc2(al1)#l2-shape [64,10]\n",
    "        \n",
    "        #activation dunction-2\n",
    "        al2=torch.sigmoid(l2)#al2-shape[64,10] which is our output\n",
    "        \n",
    "        return al2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,use_cuda,train_loader,optimizer,epoch):\n",
    "    \n",
    "    model.train()#tell the model to prepare for training\n",
    "    \n",
    "    for batchid,(data,target) in enumerate(train_loader): # get the batch\n",
    "        \n",
    "        #converting the data to [batch_size,784] from [batch_size,1,28,28]\n",
    "        data = data.reshape([data.shape[0], 784]) # [batch_size,784]\n",
    "        \n",
    "        #converting the target to onehot encoding\n",
    "        y_onehot = torch.zeros([target.shape[0], 10])  # Zero vector of shape [batch_size, 10]\n",
    "        y_onehot[range(target.shape[0]), target] = 1 \n",
    "        \n",
    "        if use_cuda:\n",
    "            data,y_onehot=data.cuda(),y_onehot.cuda() #setting the data to GPU if using Gpus\n",
    "            \n",
    "        optimizer.zero_grad()#setting the cumulative gradients to zero\n",
    "        output=model(data)#forward pass through the model\n",
    "        \n",
    "        loss=torch.mean((output-y_onehot)**2)#calculating loss MSE\n",
    "        loss.backward()#calculating gradients of the model\n",
    "        optimizer.step()#updating model parameters . this step doesnt remove stored gradients\n",
    "        \n",
    "        if batchid % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batchid * len(data), len(train_loader.dataset),\n",
    "            100. * batchid / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,use_cuda,test_loader):\n",
    "    \n",
    "    model.eval()#to tell the model to be ready for evaluation\n",
    "    \n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    \n",
    "    with torch.no_grad():#to ensure gradients are not calculated as calculating gradients is not required for testing\n",
    "        for data,target in test_loader:# getting the batch\n",
    "            \n",
    "            #converting the data to [batch_size,784] from [batch_size,1,28,28]\n",
    "            data=data.reshape([data.shape[0],784])\n",
    "            \n",
    "            #converting the target to onehot encoding\n",
    "            y_onehot=torch.zeros([target.shape[0],10])\n",
    "            y_onehot[range(target.shape[0]),target]=1\n",
    "            \n",
    "            if use_cuda:\n",
    "                data,y_onehot=data.cuda(),y_onehot.cuda()\n",
    "                \n",
    "            output=model(data)#forward pass\n",
    "            \n",
    "            test_loss+=torch.sum((output-y_onehot)**2)#sum up batch loss\n",
    "            \n",
    "            pred=output.argmax(dim=1,keepdim=True)#get index of maximum output\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()#getting total number of correct samples\n",
    "            \n",
    "        test_loss/=len(test_loader.dataset)\n",
    "        print(test_loss,100*correct/len(test_loader.dataset))#accuracy=total correct/total samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed_value):\n",
    "    #this function removes randomness and makes everything deterministic\n",
    "    #here we set the seed for torch.cuda,torch,numpy and random.\n",
    "    #torch.cuda.manual_seed_all(seed_value) ,if we are using multi-GPU then we should use this to set the seed.\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    use_cuda=False #if we have GPUs then we can set this true else False and program runs on the cpu\n",
    "    seed(0) #used to fix the randomness of the code.\n",
    "    \n",
    "    #converting the dataset to tensor and normalizing the data by subtracting mean and dividing it by standard deviation,\n",
    "    #normalizing results in the faster converging of model to optimal values.\n",
    "    \n",
    "    # x[0-255] => [0-1]\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,),(0.3081,)) #((mean),(std))    (x-mean)/std\n",
    "    ])\n",
    "    \n",
    "    data1=datasets.MNIST('../data',download=True,train=True,transform=transform)#getting the train dataset, shape=[60000,28,28]\n",
    "    data2=datasets.MNIST('../data',train=False,transform=transform)#getting the test dataset. shape=[10000,28,28]\n",
    "    \n",
    "    #loading data using torch's inbuilt dataloader\n",
    "    train_loader=torch.utils.data.DataLoader(data1,num_workers=2,batch_size=64,shuffle=True)#getting train dataloader\n",
    "    test_loader=torch.utils.data.DataLoader(data2,num_workers=2,batch_size=1000,shuffle=False)#getting test dataloader\n",
    "    \n",
    "    model=Net()\n",
    "    \n",
    "    if use_cuda:\n",
    "        model=model.cuda() # if we use GPUs we can put the model weights on GPU \n",
    "        \n",
    "    optimizer=optim.SGD(model.parameters(),lr=10)#choosing the optimizer and setting the learning rate.\n",
    "    \n",
    "    for epoch in range(1,11):\n",
    "        \n",
    "        train(model,use_cuda,train_loader,optimizer,epoch)\n",
    "        test(model,use_cuda,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.285145\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.035109\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.022455\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.016793\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.017698\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.021430\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.014029\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.008732\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.013671\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.016153\n",
      "tensor(0.1293) 92.58\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.008964\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.006504\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.009314\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.004609\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.013835\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.021412\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.010659\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.004104\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.009219\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.005467\n",
      "tensor(0.1072) 93.77\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.007609\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.011521\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.008501\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.015971\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.006641\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.011453\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.008717\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.013753\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.007982\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.008468\n",
      "tensor(0.0980) 94.12\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.013763\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.012574\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.016110\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.007436\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.006410\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.012453\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.003608\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.007062\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.009318\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.009706\n",
      "tensor(0.0957) 94.33\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.007266\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.006465\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.013682\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.007779\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.005149\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.008331\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.007827\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.007767\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.006478\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.013309\n",
      "tensor(0.0904) 94.77\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.008112\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.009326\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.008091\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.009441\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.004440\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.003714\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.007128\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.004097\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.008722\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.009239\n",
      "tensor(0.0899) 94.59\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.007615\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.005865\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.006462\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.008450\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.008097\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.006117\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.004375\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.005383\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.005090\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.004121\n",
      "tensor(0.0862) 94.92\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.009278\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.005073\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.005515\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.004313\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.006004\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.007781\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.004134\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.004941\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.012422\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.008297\n",
      "tensor(0.0845) 95.12\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.004460\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.006411\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.005159\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.012558\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.009532\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.006735\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.004614\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.013831\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.007976\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.003390\n",
      "tensor(0.0846) 95.01\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.003764\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.012725\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.004696\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.012683\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.008264\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.004166\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.005475\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.006651\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.004368\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.008717\n",
      "tensor(0.0809) 95.25\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Keras to build a NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xt,yt),(xte,yte)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xt[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=xt.reshape(60000,784).astype('float32')\n",
    "xte=xte.reshape(10000,784).astype('float32')\n",
    "xt/=255\n",
    "xte/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of unique digits\n",
    "\n",
    "Yt= np_utils.to_categorical(yt, nb_classes)\n",
    "Yte = np_utils.to_categorical(yte, nb_classes)\n",
    "yto=np.zeros([yt.shape[0],nb_classes])\n",
    "yteo=np.zeros([yte.shape[0],nb_classes])\n",
    "for i in range(yt.shape[0]):\n",
    "    yto[i][yt[i]]=1\n",
    "for i in range(yte.shape[0]):\n",
    "    yteo[i][yte[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 12:12:17.317551: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-20 12:12:17.317592: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-20 12:12:17.317619: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (localhost.localdomain): /proc/driver/nvidia/version does not exist\n",
      "2022-07-20 12:12:17.317945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()                        #Linear stacking of layers\n",
    "\n",
    "model.add(Dense(512,input_shape=(784,)))  #First layer with 512 nodes\n",
    "model.add(Activation('relu'))             #Relu activation function \n",
    "\n",
    "model.add(Dense(50))                      #second layer with 50 nodes\n",
    "model.add(Activation('relu'))             #relu activation layer\n",
    "model.add(Dropout(0.2))                   #20% dropout of randomly selected nodes\n",
    "\n",
    "model.add(Dense(10))                      #Final layer with 10 nodes and\n",
    "model.add(Activation('softmax'))          #softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                25650     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 428,080\n",
      "Trainable params: 428,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2733 - accuracy: 0.9198\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1080 - accuracy: 0.9677\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.9776\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.0551 - accuracy: 0.9836\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0434 - accuracy: 0.9867\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0343 - accuracy: 0.9895\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0314 - accuracy: 0.9893\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0258 - accuracy: 0.9914\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0210 - accuracy: 0.9930\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0183 - accuracy: 0.9941\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0156 - accuracy: 0.9947\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0144 - accuracy: 0.9953\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0156 - accuracy: 0.9949\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0118 - accuracy: 0.9959\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0109 - accuracy: 0.9967\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0113 - accuracy: 0.9963\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0115 - accuracy: 0.9963\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0099 - accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51e33b7520>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=xt,y=yto,batch_size=64,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 977us/step - loss: 0.0969 - accuracy: 0.9828\n",
      "Test score: 0.09686155617237091\n",
      "Test accuracy: 0.9828000068664551\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(xte,yteo)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 857us/step\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "preds=model.predict(xte)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "print(preds[1].argmax(),yteo[1].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=np.array([preds[i].argmax() for i in range(len(preds))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99292035]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_true=yte,y_pred=preds,labels=[1],average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98854626]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(y_true=yte,y_pred=preds,labels=[1],average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                25650     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 428,080\n",
      "Trainable params: 428,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#categorical cross entropy loss function is used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding convolution and maxpooling layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (60000, 28, 28, 1)\n",
      "Testing matrix shape (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of unique digits\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()                                 # Linear stacking of layers\n",
    "\n",
    "# Convolution Layer 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer01 = Activation('relu')                     # activation\n",
    "model.add(convLayer01)\n",
    "\n",
    "# Convolution Layer 2\n",
    "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer02)\n",
    "\n",
    "# Convolution Layer 3\n",
    "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer03 = Activation('relu')                     # activation\n",
    "model.add(convLayer03)\n",
    "\n",
    "# Convolution Layer 4\n",
    "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer04)\n",
    "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
    "\n",
    "# Fully Connected Layer 5\n",
    "model.add(Dense(512))                                # 512 FCN nodes\n",
    "model.add(BatchNormalization())                      # normalization\n",
    "model.add(Activation('relu'))                        # activation\n",
    "\n",
    "# Fully Connected Layer 6                       \n",
    "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
    "model.add(Dense(10))                                 # final 10 FCN nodes\n",
    "model.add(Activation('softmax'))                     # softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10, 10, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 597,738\n",
      "Trainable params: 596,330\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = gen.flow(X_train, Y_train, batch_size=128)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5973/1017124850.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator, steps_per_epoch=60000//128, epochs=5, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 29s 60ms/step - loss: 0.1263 - accuracy: 0.9607 - val_loss: 0.0545 - val_accuracy: 0.9840\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 28s 60ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 0.0394 - val_accuracy: 0.9864\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 28s 60ms/step - loss: 0.0392 - accuracy: 0.9888 - val_loss: 0.0381 - val_accuracy: 0.9870\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 28s 60ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.0269 - val_accuracy: 0.9920\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 28s 60ms/step - loss: 0.0310 - accuracy: 0.9903 - val_loss: 0.0376 - val_accuracy: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f14b5b62fd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=60000//128, epochs=5, verbose=1, \n",
    "                    validation_data=test_generator, validation_steps=10000//128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0375 - accuracy: 0.9881\n",
      "Test score: 0.03750322386622429\n",
      "Test accuracy: 0.988099992275238\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
